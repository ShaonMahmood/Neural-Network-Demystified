{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training Data features (Hours(sleep), Hours(study))\n",
    "X = np.array([[3,5],[5,1],[7,2]])\n",
    "# training Outputs (scores on test)\n",
    "y = np.array([[73],[82],[91]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the values or scale the values(feature scalling) \n",
    "# X = X/max(X), y = y/max(y)\n",
    "\n",
    "column_wise_max_X_values = np.max(X,axis=0)\n",
    "X = X/column_wise_max_X_values\n",
    "\n",
    "# highest score is 100\n",
    "y = y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class neural network\n",
    "class NeuralNet:\n",
    "    \n",
    "    def __init__(self, inputLayersize=2, outputlayerSize=1, hiddenLayerSize=3):\n",
    "        # set network hyparameters\n",
    "        self.inputLayersize = inputLayersize\n",
    "        self.outputlayerSize = outputlayerSize\n",
    "        self.hiddenLayerSize = hiddenLayerSize\n",
    "        \n",
    "        # weights parameters\n",
    "        self.W1 = np.random.randn(inputLayersize,hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(hiddenLayerSize,outputlayerSize)\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self, z):\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        # propagate inputs through network\n",
    "        self.z2 = np.dot(X,self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3)\n",
    "        return yHat\n",
    "        \n",
    "    def costFunction(self, X, y):\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5 * sum((y-self.yHat)**2)\n",
    "        return J\n",
    "    \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        self.yHat = self.forward(X)\n",
    "        delta3 = np.multiply(-(y - self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3,self.W2.T) * self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T,delta2)\n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    def getParameters(self):\n",
    "        # transform to 1 D array and then concatenate\n",
    "        params = np.concatenate((self.W1.ravel(),self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParameters(self, params):\n",
    "        w1_start = 0\n",
    "        w1_end = self.inputLayersize * self.hiddenLayerSize\n",
    "        self.W1 = np.reshape(params[w1_start:w1_end], (self.inputLayersize, self.hiddenLayerSize))\n",
    "        w2_end = w1_end + (self.hiddenLayerSize * self.outputlayerSize)\n",
    "        self.W2 = np.reshape(params[w1_end:w2_end],(self.hiddenLayerSize, self.outputlayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, Y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X,y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
    "    \n",
    "def computrNumericalGradient(NN, X, y):\n",
    "    initialParams = NN.getParameters()\n",
    "    numgrad = np.zeros(initialParams.shape)\n",
    "    perturb = np.zeros(initialParams.shape)\n",
    "    \n",
    "    epsilon = 1e-4\n",
    "    \n",
    "    for p in range(len(initialParams)):\n",
    "        perturb[p] = epsilon\n",
    "        NN.setParameters(initialParams+perturb)\n",
    "        loss2 = NN.costFunction(X,y)\n",
    "        \n",
    "        NN.setParameters(initialParams-perturb)\n",
    "        loss1 = NN.costFunction(X,y)\n",
    "        \n",
    "        numgrad[p] = (loss2-loss1) / (2*epsilon)\n",
    "        \n",
    "        perturb[p] = 0\n",
    "        \n",
    "    NN.setParameters(initialParams) # return to original\n",
    "    return numgrad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numgrad = computrNumericalGradient(NN, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01238686,  0.02234721,  0.05983316,  0.00801623,  0.00951703,\n",
       "        0.03212099, -0.17963786, -0.21439812, -0.20731077])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = NN.computeGradients(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01238686,  0.02234721,  0.05983316,  0.00801623,  0.00951703,\n",
       "        0.03212099, -0.17963786, -0.21439812, -0.20731077])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fd57b804d11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnumgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'norm' is not defined"
     ]
    }
   ],
   "source": [
    "norm(grad - numgrad) / norm(grad + numgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
